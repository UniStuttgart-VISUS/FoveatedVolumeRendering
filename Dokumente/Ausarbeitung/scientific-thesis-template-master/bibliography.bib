% Encoding: UTF-8

%%%
%
%Beim Erstellen der Bibtex-Datei wird empfohlen darauf zu achten, dass die DOI aufgeführt wird.
%
%%%

@Book{WSPA,
  author    = {Sanjiva Weerawarana and Francisco Curbera and Frank Leymann and Tony Storey and Donald F. Ferguson},
  title     = {Web Services Platform Architecture : SOAP, WSDL, WS-Policy, WS-Addressing, WS-BPEL, WS-Reliable Messaging, and More},
  year      = {2005},
  publisher = {Prentice Hall PTR},
  isbn      = {0131488740},
  doi       = {10.1.1/jpb001},
}


% !! DO NOT USE `label =   {ASF}` in other Misc entries !!

@Misc{ApacheODE,
  author = {{The Apache Software Foundation}},
  title =  {Apache ODE\texttrademark{} -- The Orchestration Director Engine},
  year =   {2016},
  label =  {ASF},
  url =    {http://ode.apache.org}
}

@Article{RVvdA2016,
  author =    {H.A. Reijers and I. Vanderfeesten and W.M.P. van der Aalst},
  title =     {The effectiveness of workflow management systems: A longitudinal study},
  journal =   {International Journal of Information Management},
  year =      {2016},
  volume =    {36},
  number =    {1},
  pages =     {126--141},
  month =     feb,
  doi =       {10.1016/j.ijinfomgt.2015.08.003},
  publisher = {Elsevier {BV}}
}

@Book{Duden2001,
  author    = {Duden},
  title     = {Die Deutsche Rechtschreibung},
  year      = {2001},
  edition   = {22., völlig neu bearbeitete und erweiterte Auflage},
  note      = {Aktualisierter Nachdruck},
  publisher = {Dudenverlag},
  isbn      = {3-411-04012-2},
}

@Article{doi:10.1111/cgf.13320,
  author   = {Englund, R. and Ropinski, T.},
  title    = {Quantitative and Qualitative Analysis of the Perception of Semi-Transparent Structures in Direct Volume Rendering},
  journal  = {Computer Graphics Forum},
  volume   = {37},
  number   = {6},
  pages    = {174-187},
  doi      = {10.1111/cgf.13320},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13320},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13320},
  abstract = {Abstract Direct Volume Rendering (DVR) provides the possibility to visualize volumetric data sets as they occur in many scientific disciplines. With DVR semi-transparency is facilitated to convey the complexity of the data. Unfortunately, semi-transparency introduces challenges in spatial comprehension of the data, as the ambiguities inherent to semi-transparent representations affect spatial comprehension. Accordingly, many techniques have been introduced to enhance the spatial comprehension of DVR images. In this paper, we present our findings obtained from two evaluations investigating the perception of semi-transparent structures from volume rendered images. We have conducted a user evaluation in which we have compared standard DVR with five techniques previously proposed to enhance the spatial comprehension of DVR images. In this study, we investigated the perceptual performance of these techniques and have compared them against each other in a large-scale quantitative user study with 300 participants. Each participant completed micro-tasks designed such that the aggregated feedback gives insight on how well these techniques aid the user to perceive depth and shape of objects. To further clarify the findings, we conducted a qualitative evaluation in which we interviewed three experienced visualization researchers, in order to find out if we can identify the benefits and shortcomings of the individual techniques.},
  keywords = {scientific visualization, volume visualization, Computing methodologies → Perception; Human-centred computing → Scientific visualization},
}

@Proceedings{foveated-3d-graphics,
  title     = {Foveated 3D Graphics},
  year      = {2012},
  publisher = {ACM SIGGRAPH Asia},
  month     = {November},
  url       = {https://www.microsoft.com/en-us/research/publication/foveated-3d-graphics/},
  abstract  = {

We exploit the falloff of acuity in the visual periphery to accelerate graphics computation by a factor of 5-6 on a desktop HD display (19201080). Our method tracks the user’s gaze point and renders three image layers around it at progressively higher angular size but lower sampling rate. The three layers are then magnified to display resolution and smoothly composited. We develop a general and efficient antialiasing algorithm easily retrofitted into existing graphics code to minimize “twinkling” artifacts in the lower-resolution layers. A standard psychophysical model for acuity falloff assumes that minimum detectable angular size increases linearly as a function of eccentricity. Given the slope characterizing this falloff, we automatically compute layer sizes and sampling rates. The result looks like a full-resolution image but reduces the number of pixels shaded by a factor of 10-15. We performed a user study to validate these results. It identifies two levels of foveation quality: a more conservative one in which users reported foveated rendering quality as equivalent to or better than non-foveated when directly shown both, and a more aggressive one in which users were unable to correctly label as increasing or decreasing a short quality progression relative to a high-quality foveated reference. Based on this user study, we obtain a slope value for the model of 1.32-1.65 arc minutes per degree of eccentricity. This allows us to predict two future advantages of foveated rendering: (1) bigger savings with larger, sharper displays than exist currently (e.g. 100 times speedup at a field of view of 70° and resolution matching foveal acuity), and (2) a roughly linear (rather than quadratic or worse) increase in rendering cost with increasing display field of view, for planar displays at a constant sharpness.


},
  author    = {Guenter, Brian and Finch, Mark and Drucker, Steven and Tan, Desney and Snyder, John},
}

@Article{doi:10.1111/cgf.13150,
  author   = {Weier, M. and Stengel, M. and Roth, T. and Didyk, P. and Eisemann, E. and Eisemann, M. and Grogorick, S. and Hinkenjann, A. and Kruijff, E. and Magnor, M. and Myszkowski, K. and Slusallek, P.},
  title    = {Perception-driven Accelerated Rendering},
  journal  = {Computer Graphics Forum},
  volume   = {36},
  number   = {2},
  pages    = {611-643},
  doi      = {10.1111/cgf.13150},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13150},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13150},
  abstract = {Abstract Advances in computer graphics enable us to create digital images of astonishing complexity and realism. However, processing resources are still a limiting factor. Hence, many costly but desirable aspects of realism are often not accounted for, including global illumination, accurate depth of field and motion blur, spectral effects, etc. especially in real-time rendering. At the same time, there is a strong trend towards more pixels per display due to larger displays, higher pixel densities or larger fields of view. Further observable trends in current display technology include more bits per pixel (high dynamic range, wider color gamut/fidelity), increasing refresh rates (better motion depiction), and an increasing number of displayed views per pixel (stereo, multi-view, all the way to holographic or lightfield displays). These developments cause significant unsolved technical challenges due to aspects such as limited compute power and bandwidth. Fortunately, the human visual system has certain limitations, which mean that providing the highest possible visual quality is not always necessary. In this report, we present the key research and models that exploit the limitations of perception to tackle visual quality and workload alike. Moreover, we present the open problems and promising future research targeting the question of how we can minimize the effort to compute and display only the necessary pixels while still offering a user full visual experience.},
  keywords = {Categories and Subject Descriptors (according to ACM CCS), I.3.3 Computer Graphics: Picture/Image Generation—Line and curve generation},
}

@InProceedings{Lu:2006:VCU:2384796.2384814,
  author    = {Lu, Aidong and Maciejewski, Ross and Ebert, David S.},
  title     = {Volume Composition Using Eye Tracking Data},
  booktitle = {Proceedings of the Eighth Joint Eurographics / IEEE VGTC Conference on Visualization},
  year      = {2006},
  series    = {EUROVIS'06},
  publisher = {Eurographics Association},
  location  = {Lisbon, Portugal},
  isbn      = {3-905673-31-2},
  pages     = {115--122},
  doi       = {10.2312/VisSym/EuroVis06/115-122},
  url       = {http://dx.doi.org/10.2312/VisSym/EuroVis06/115-122},
  acmid     = {2384814},
  address   = {Aire-la-Ville, Switzerland, Switzerland},
  numpages  = {8},
}

@InProceedings{Levoy:1990:GVR:91385.91449,
  author    = {Levoy, Marc and Whitaker, Ross},
  title     = {Gaze-directed Volume Rendering},
  booktitle = {Proceedings of the 1990 Symposium on Interactive 3D Graphics},
  year      = {1990},
  series    = {I3D '90},
  publisher = {ACM},
  location  = {Snowbird, Utah, USA},
  isbn      = {0-89791-351-5},
  pages     = {217--223},
  doi       = {10.1145/91385.91449},
  url       = {http://doi.acm.org/10.1145/91385.91449},
  acmid     = {91449},
  address   = {New York, NY, USA},
  numpages  = {7},
}

@InProceedings{Patney:2016:PFV:2929464.2929472,
  author    = {Patney, Anjul and Kim, Joohwan and Salvi, Marco and Kaplanyan, Anton and Wyman, Chris and Benty, Nir and Lefohn, Aaron and Luebke, David},
  title     = {Perceptually-based Foveated Virtual Reality},
  booktitle = {ACM SIGGRAPH 2016 Emerging Technologies},
  year      = {2016},
  series    = {SIGGRAPH '16},
  publisher = {ACM},
  location  = {Anaheim, California},
  isbn      = {978-1-4503-4372-5},
  pages     = {17:1--17:2},
  doi       = {10.1145/2929464.2929472},
  url       = {http://doi.acm.org/10.1145/2929464.2929472},
  acmid     = {2929472},
  address   = {New York, NY, USA},
  articleno = {17},
  keywords  = {augmented reality, foveated rendering, perceptually-based, virtual reality},
  numpages  = {2},
}

@InProceedings{Koskela:2017:FIP:3145749.3149423,
  author    = {Koskela, Matias and Immonen, Kalle and Viitanen, Timo and J\"{a}\"{a}skel\"{a}inen, Pekka and Multanen, Joonas and Takala, Jarmo},
  title     = {Foveated Instant Preview for Progressive Rendering},
  booktitle = {SIGGRAPH Asia 2017 Technical Briefs},
  year      = {2017},
  series    = {SA '17},
  publisher = {ACM},
  location  = {Bangkok, Thailand},
  isbn      = {978-1-4503-5406-6},
  pages     = {10:1--10:4},
  doi       = {10.1145/3145749.3149423},
  url       = {http://doi.acm.org/10.1145/3145749.3149423},
  acmid     = {3149423},
  address   = {New York, NY, USA},
  articleno = {10},
  keywords  = {eye tracking, foveated rendering, preview, progressive rendering},
  numpages  = {4},
}

@Misc{Dr.MichaelKrone2016/2017,
  author       = {Dr. Michael Krone, Dr. Guido Reina},
  title        = {Vorlesungsfolien in Computergraphik, Raytracing},
  year         = {2016 / 2017},
  organization = {Institut für Visualisierung und Interaktive Systeme der Universität Stuttgart},
}

@WWW{tobii,
  author       = {tobii},
  title        = {What is Eyetracking?},
  url          = {https://www.tobii.com/tech/technology/what-is-eye-tracking/},
  organization = {Tobii AB},
  urldate      = {2018-09-12},
}

@WWW{tobiisdk,
  author       = {tobiisdk},
  title        = {Eyetracking Common Concepts, Tobii Pro SDK},
  url          = {http://developer.tobiipro.com/commonconcepts.html},
  organization = {Tobii AB},
}

@WWW{tobiipro,
  author       = {tobiipro},
  title        = {How to tobii eye trackers work},
  url          = {https://www.tobiipro.com/learn-and-support/learn/eye-tracking-essentials/how-do-tobii-eye-trackers-work/},
  organization = {Tobii AB},
  urldate      = {2018-09-12},
}

@Article{Moth,
  author  = {Daniel Moth},
  title   = {Warp or Wavefront of GPU threads},
  url     = {https://blogs.msdn.microsoft.com/nativeconcurrency/2012/03/26/warp-or-wavefront-of-gpu-threads/},
  urldate = {2018-09-15},
}

@Comment{jabref-meta: databaseType:biblatex;}
