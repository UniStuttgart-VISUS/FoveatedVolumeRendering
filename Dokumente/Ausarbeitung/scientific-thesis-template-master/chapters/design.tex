% Entwurf: Projekt, Raytracer, (Auswahl des) Eyetracker, Vorüberlegungen zur Umsetzung / Integration, Grundidee zur Umsetzung
% Entwurfsziele an die Umsetzungs
\chapter{Entwurf}\label{chap::design}
Die Implementierung dieser Arbeit beruht auf einem Visual Studio Projekt zum Volumen Rendering von Valentin Bruder.
Der erste Abschnitt des Entwurfskapitels beinhaltet den Ausgangspunkt der Implementierung dieser Arbeit in Form einer Beschreibung des ursprünglichen Projekts.
Dies umfasst die allgemeine Architektur der Anwendung und die Umsetzung des Volumenrenderings durch eine Implementierung eines Raycasters als OpenCL Kernel.
Der zweite Abschnitt des Kapitels umfasst Überlegungen für die Erweiterung des Projektes, bezüglich des Ausgangspunktes wie er im ersten Abschnitt beschrieben wurde und dem Ziel dieser Arbeit, sowie die daraus entstandenen Arbeitspakete und die Ansätze für ihre Integration in das bestehende Projekt.

\section{Projekt}\label{sec::proj}
% QT
Das Visual Studio Projekt, welches als Ausgangspunkt dient, ist eine auf QT basierende Anwendung.
QT ist ein vollständiges Cross-Platform Softaware Development Framework, welches in c++ entwickelt wurde, und ermöglicht die einfache Erstellung von Anwendungen mit Benutzeroberflächen und bietet außerdem eine Vielzahl von Bibliotheken, die für eine leichtere und schnellere Entwicklung von Programmen genutzt werden können.

% Struktur von QT
Die Hauptelemente für die QT Benutzeroberfläche sind QT Widgets.
Widgets können Daten darstellen und Nutzereingaben erkennen.
Außerdem stellt ein Widget selbst ein Container für weitere Widgets dar, welche in diesem gruppiert werden.
Innerhalb eines Widgets können Elemente platziert werden, welche Informationen, mögliche Operationen oder Nutzereingaben repräsentieren.
Für die bequeme Erstellung der grafischen Oberfläche bietet QT die Anwendung QT Designer.
Der QT Designer ermöglicht es, Widgets und andere Bausteine der grafischen Oberfläche per Drag und Drop anzuordnen.
Die durch den QT Designer definierte Oberfläche kann abgespeichert werden und wird von QT verwendet, um eine c++ Header File zu erstellen.
Dies ermöglicht es die verschiedenen Elemente der grafischen Oberfläche an die Logik der Anwendung zu binden.
\todo{Quelle zu QT einfügen.}

% Struktur des Projekts (verschiedene Widgets)
Das Projekt ist dementsprechend in c++ geschrieben und die grafische Oberfläche wurde mit Hilfe des QT Designers erstellt.
Die Oberfläche selbst hat eine Menüleiste, die es unter Anderem ermöglicht, Volumendaten oder Transferfunktionen zu laden oder auch aktive Transferfunktionen zu speichern sowie das Erstellen eines Screenshots des zuletzt berechneten Bildes.
Den Großteil der grafischen Oberfläche wird durch das Volumenrenderwidget ausgefüllt.
Das Volumenrenderwidget ist ein QT OpenGL Widget und kann für das Darstellen von OpenGL Grafiken verwendet werden.
Die berechneten Grafiken werden mit Hilfe des Volumenrenderwidgets dargestellt.
Neben dem Volumenrenderwidget gibt es noch ein Widget, welches in drei weitere Widgets unterteilt ist, mit denen Parameter für das Volumenrendering gesetzt werden können.
Das erste von ihnen ermöglicht das variieren der Abtastrate im Bildraum, also die Anzahl der Strahlen, die ausgesendet werden, sowie das Setzen der allgemeinen Abtastrate der ausgesendeten Strahlen.
Außerdem können hier weitere Rendering Parameter festgelegt werden, wie die Hintergrundfarbe oder ob Voxel beim Abtasten interpoliert werden.
Das zweite Widget ist ein Farbenrad, welches für die einfache Auswahl der Farben einzelner Kontrollpunkte der Transferfunktion verwendet werden kann.
Das dritte Widget ermöglicht schließlich das Setzen von Kontrollpunkten der Transferfunktion innerhalb eines Diagramms.
Die x-Richtung gibt die Dichte, auf die sich ein Kontrollpunkt bezieht an.
Die y-Richtung gibt seinen Opazitätswert an.
Die Werte zwischen zwei Kontrollpunkten werden entweder linear oder quadratisch interpoliert.
Daher gibt es immer mindestens einen Kontrollpunkt für den Dichtewert null und einen Kontrollpunkt für den Dichtewert eins.
\todo{Bitte auf Richtigkeit von diesem Teil prüfen, wie: Interpolation von Voxel und Einstellen der Transferfunkton.}

% Speziell VolumeRenderWidget: OpenCL, OpenGL Host Code
Das Volumenrenderwidget ist ein OpenGL Widget und für die Darstellung der berechneten Bilder zuständig.
Das QT Framework erlaubt es, das Widget in c++ Code mit Logik zu verknüpfen.
Dafür existiert in dem Projekt eine Klasse VolumeRenderWidget, welche von QOpenGLWidget erbt.
Die grundsätzliche Funktionalität zum Rendern in diesem Widget wird durch die Methode \texttt{paintGL()} ausgeführt.
Innerhalb dieser Methode wird der Code geschrieben, der für die Darstellung des Bildes nötig ist.
Das Darstellen auf dem Bildschirm beziehungsweise in dem Widget wird durch OpenGL realisiert.
OpenGL zeichnet dabei aber lediglich eine durch einen OpenCL Kernel zuvor generierte Textur auf ein Fullscreen Quad.
Das Management von OpenCL wird hier durch ein Objekt der Klasse \texttt{volumerendercl} geregelt.
Innerhalb der \texttt{paintGL()} Methode wird eine Methode dieses Objekts zum Starten des OpenCL Kernels für den Raycast des Volumenrenderings aufgerufen.
Das \texttt{volumerendercl} Objekt regelt die Handhabung der verschiedenen Parameter für den Kernel und die Unterteilung der übergebenen Anzahl an Strahlen in x- und y-Richtung, welche der Anzahl zu startenden Work-Items entspricht, in Work-Groups.
Außerdem startet es den Kernel, synchronisiert einen gemeinsamen Stopp und speichert die benötigte Zeit der letzten Ausführung des Kernels.
Die berechneten Werte der einzelnen Work-Items können bei der Ausführung des Kernels direkt in die OpenGL Textur geschrieben werden.
Daher kann nach der Ausführung der aufgerufenen Methode des \texttt{volumerendercl} Objekts die Textur direkt gezeichnet werden.
Mit Hilfe von QT Funktionen und der Information über die Ausführungszeit des Kernels werden anschließend noch ein paar Overlays gezeichnet.
Unter Anderem eine Anzeige der ungefähren möglichen Anzahl an Bildern pro Sekunde der letzten Ausführungen, um die Ausführungsdauer des Kernels abschätzen zu können.

% Raycaster: Raycastkernel
\subsection*{Raycaster}\label{ss::rc}
% Raycaster: wichtige Parameter: in, out; Ungefährerer Aufbau: Sampling Loop durch das Volumen;
Der eigentliche Raycast passiert in einem OpenCL Kernel.
Die OpenCL Objekte werden von dem \texttt{volumerendercl} Objekt gehandhabt, dessen Methoden innerhalb der \texttt{paintGL()} Methode aufgerufen werden.
Das \texttt{volumerendercl} Objekt regelt auch die Übergabe der Parameter an den Raycast Kernel.
Dies sind Parameter wie Volumendaten, Transferfunktionswerte und Strahlabtastrate zum lesen, sowie eine 2D-Textur zum schreiben für die berechneten Farbwerte der einzelnen Work-Items.
Jedes Work-Item besitzt eine 2D-ID, die einer Position in der Ausgabetextur zugewiesen bekommt.
Ein Work-Item ist für das Abtasten eines Strahls verantwortlich.
Ein Strahl hat als Ursprung die Position der Kamera und entsprechend seiner ID, beziehungsweise Texturkoordinaten, wird seine Richtung bestimmt.
Abhängig von der Abtastrate des Strahls, berechnet sich die Schrittgröße für das Abtasten. 
Ausgehend von dem Schnittpunkt des Strahls mit der Bildebene wird nun in einer Schleife der Strahl schrittweise abgetastet.
Dabei wird für jeden Schritt die aktuelle Position bestimmt, welche normiert und dann dafür genutzt wird, um in dem 3D-Volumen Objekt den Dichtewert für diese Position zu bestimmen.
Mit dem Dichtewert und den Daten der Transferfunktion wird anschließend ein Farbwert berechnet.
Dieser Farbwert wird mit den bisherigen gesammelten Farbwerten des Strahls verrechnet, so dass am Ende der Abtastschleife ein einziger Farbwert für den Strahl existiert.
Der Farbwert wird zum Schluss an die entsprechende Texturkoordinate in der Ausgabetextur gespeichert.
\todo{Bild für das Abtasten des Strahls einfügen. Entweder hier oder bei Basics mit Volumenrendering und dann dorthin verweisen.}

%  Raycaster: Spezielle Eigenschaften, die aktiviert und deaktiviert werden können: ESS, Interpolation, AO
Der Raycast Kernel hat außer der grundlegenden Raycast Funktion noch weitere Eigenschaften, die die Performanz der Ausführung und die Qualität des Bildes verbessern.
So kann \emph{Empty Space Skipping} aktiviert werden, um größere Bereiche mit rein transparenten Voxeln zu überspringen.
Dies wird mit Hilfe eines zuvor gröber Berechneten Volumen ermöglicht.
Da das Volumen nur eine begrenzte Auflösung hat aber an einer beliebigen Position ein Wert aus dieser 3D-Textur abgerufen werden kann, muss angegeben werden, wie dieser Wert abhängig von den umliegenden Voxel bestimmt wird.
Daher kann hier gewählt werden, dass beim Auslesen des Dichtewerts an einer bestimmten Position des Volumens, dieser interpoliert wird.
Außerdem kann eine Orthografische Sicht des Volumens aktiviert werden, indem die Strahlen parallel ausgesendet werden und für solide Oberflächen gibt es die Möglichkeit, den Effekt der \emph{Ambient Occlusion} darzustellen.
\todo{Beschreibung der Funktionsweise des Raycasters für das Volumenrendering in dem Projekt.}

\section{Arbeitspakete und Integration}\label{sec::workpacks}
Ausgehend von der in Abschnitt \ref{sec::proj} beschriebenen Ausgangslage des Projekts, wurden einige Vorüberlegungen und Arbeitspakete erstellt, welche das Ziel hatten, das Projekt so zu erweitern, dass die Aspekte des wahrnehmungsorientierten Volumenrendering veranschaulicht und umgesetzt werden können.
Im folgenden werden die für dieses Ziel entstandenen Vorüberlegungen und daraus erstellte Arbeitspakete aufgeführt und die dazugehörigen Ansätze zur Integration in das bestehende Projekt skizziert.
Genauere Angaben zur Implementierung bestimmter Arbeitspakete werden im Kapitel \ref{chap::impl} vorgestellt.

\subsection*{Einarbeitung in das Projekt}
Das erste Arbeitspaket, welches nicht zu vernachlässigen ist, war die Einarbeitung in das Projekt beziehungsweise in die bestehende Implementierung.
Dies erforderte das Einarbeiten in einige Grundlagen der c++ Programmierung sowie das Einarbeiten in den grundlegenden Umgang mit dem QT Framework.
Da das Projekt ein Visual Studio Projekt ist und Programmierschnittstellen wie OpenCL oder auch QT verwendet, war eine kleine Einarbeitung in das richtige Verlinken der Bibliotheken mit dem Projekt auch Teil von diesem Arbeitspaket.

\subsection*{Simulieren der Blickposition}
Um die Eigenschaften des visuellen Wahrnehmungssystems des Menschen auszunutzen, dass die Genauigkeit des Auges außerhalb des zentralen Bereichs stark abnimmt, ist es notwendig, die Blickposition beziehungsweise den fokussierten Punkt auf dem Bildschirm zu kennen.
Ein Eyetracker kann dies messen und die Daten der Anwendung zur Verfügung stellen.
Da die Einbindung eines Eyetrackers für die ersten Arbeitsschritte, wie das Implementieren erster Versuche, den Raycast Kernel wahrnehmungsorientiert umzuschreiben, nicht notwendig ist, sondern zum Teil auch erschwert, kann der Blickpunkt vorerst sehr gut mit der Maus simuliert werden.
QT Widgets können auf Maus und Tastatureingaben reagieren.
Daher war das erste Arbeitspaket das Erkennen von Mausbewegungen innerhalb des Volumerenderwidgets und das Abspeichern der letzten erkannten Mausposition in einer globalen Variable.
Zusätzlich musste diese dem OpenCL Kernel, der den Raycast ausführt, zur Verfügung gestellt werden.
Daher wurde die Mausposition dem OpenCL Kernel als Parameter übergeben.

\subsection*{Reduzierung der Strahlabtastrate im fovealen Bereich}
Da die Mausposition dem Kernel nun zur Verfügung steht, können erste Implementierungsversuche für einen wahrnehmungsorientierten Raycast unternommen werden.
Das ursprüngliche Projekt stellt zwei Parameter zur Verfügung, welche auf zwei verschiedene Arten die Ausführungszeit des Kernels beeinflussen.
Die Abtastrate der jeweiligen Strahlen und die Anzahl der Strahlen in x- und y-Richtung.
Da das Verändern der Anzahl an Strahlen in x- und y- Richtung das gesamte Bild betrifft und dies nicht einfach abhängig von dem Abstand zur Mausposition verändert werden kann, ist die Anpassung der Abtastrate einzelner Strahlen für den Anfang einfacher zu gestalten.
Aus diesem Grund heraus entstand das nächste Arbeitspaket.
Dieses umfasst die Verwendung der an den Raycast Kernel übergebenen Mausposition, um die Abtastrate der jeweiligen Strahlen, abhängig von der Distanz der Bildposition des Strahls zu der Position des Mauszeigers, zu reduzieren.
Die Anpassung des Kernels hat zur Folge, dass für jeden Strahl abhängig seiner Distanz zum Mauszeiger eine eigene Abtastrate berechnet wird.
Aufgrund dessen, dass wie im Abschnitt \ref{ss::rc} die Work-Items den Texel zugeordnet sind und die Work-Groups quadratisch angeordnet sind, sollte dies bewirken, dass die Work-Items innerhalb der selben Work-Group eine ähnliche Abtastrate für ihren Strahl berechnen und die gesamte Work-Group früher terminieren kann.
Da der Kernel erst beendet wird, wenn alle Work-Groups ihre Arbeit abgeschlossen haben, bewirkt eine schnellere Ausführung einzelner Work-Groups eine insgesamt schnellere Ausführung des Kernels.
Dementsprechend bewirkt dies auch eine bessere Performanz beim Berechnen des Bildes.
Die Mausposition wurde in Bildkoordinaten, bezüglich des Volumerenderwidgets dem Kernel übergeben.
Da die Anzahl der gestarteten Work-Items den Ausmaßen des Volumerenderwidgets entspricht, entspricht auch die ID eines Work-Items einer Bildkoordinate.
Daher konnte die Entfernung der Work-Items zum Mauszeiger einfach berechnet werden und die Abtastrate abhängig von dieser Distanz angepasst.
Erste Tests der Implementierung haben eine Erhöhung der im Volumerenderwidget durchschnittlichen angezeigten Bilder pro Sekunde ergeben.
Die Verminderung der Abtastrate machte sich nur bei dünnen Volumen visuell bemerkbar, da hier die einige Strahlen einen Teil des Volumen teilweise gar nicht abgetastet haben.

\subsection*{Reduzierung der Strahldichte im fovealen Bereich}
Trotz der Reduzierung der Abtastrate der Strahlen, wird immer noch die gleiche Anzahl an Work-Items gestartet.
Dies ermöglicht einen weitere Möglichkeit die Ausführungszeit des Kernels zu reduzieren, indem die Anzahl der Strahlen und somit auch die Auflösung des berechneten Bildes variiert wird.
Weniger zu berechnenden Strahlen bedeutet hier auch weniger benötigte Work-Items und Work-Groups, die ausgeführt werden müssen.
Weniger Work-Groups bedeutet dann auch eine geringere Ausführungszeit des Raycast Kernels.

Die erste Überlegung diesbezüglich war es, eine Art virtuelle Linse vor die Bildebene zu setzen, die die Strahlen so auf der Bildebene verteilt, dass an der Mausposition eine höhere Strahldichte existiert und diese mit größerem Abstand zur Mausposition abnimmt.
So könnte bei einer geringeren Anzahl an Strahlen, an der Mausposition, die den Blickpunkt simuliert, trotzdem die maximale Auflösung erreicht werden.
Die Bildpunkte die dann nicht direkt von einem Strahl abgedeckt werden, müssten interpoliert werden.
Dieser Ansatz wurde aber verworfen, da die Implementierung der virtuellen Linse und der anschließenden Interpolation sich als zu aufwändig erwies und es deutlich einfacher umzusetzende Alternativen gibt.

% Neue Idee: Zwei verschiedene Kernelaufrufe. Der erste berechnet das Bild mit einem viertel der Auflösung über den gesamten Texturbereich, der zweite berechnet das Bild mit der normalen Auflösung aber nur in einem kleinen Bereich um die Mausposition.
% Danach werden beide übereinander platziert.
% Problem: Bilder in verschiedenen Auflösung. Daher Mausposition normieren auf [0,1]^2. Reduzieren der Strahlsamples wurde bei diesem Ansatz nicht verwendet.
% -> Arbeitspaket: Berechnen des Bildes in zwei verschiedenen Auflösungen und Zusammenfügen beider für ein Bild in gesamter Auflösung. 

\subsection*{Indize-Mapping}
% Ziel: Drei unterschiedliche Auflösungen, die übereinander gelegt werden.
% Mit normierten Koordinaten zu rechnen war aufwändig
% -> drei Berechnungen auf dem gesamten Bild aber je nach Auflösung werden Work-Items schon früh discarded.
% -> erster Test hat gezeigt, dass 1. Drei Kernel Enqueues nacheinander, die jeweils den Raycast machen, aufwändig sind und 2. das discarden von Work-Items keinerlei Performance bringt. Lag daran, dass Work-Items in verschiedenen Work-Groups sind und auch wenn alle bis auf eines früh discarded, muss der gesamte Thread-Block (auf den eine Work-Group vermutlich gemappt ist) weiterarbeiten.
% -> Daher: Zwei oder mehr Raycast Kernel Aufrufe wollte vermeiden, wegen möglichen Overhead und neuer Ansatz: Drei unterschiedlich aufgelöste Bildbereiche bei einem Renderdurchlauf durch das Mapping von Indizes.
% -> Arbeitspaket: Mapping von Indizes um bei einem einzigen Raycast Kernel Aufruf trotzdem drei verschieden aufgelöste Bereiche zu erreichen.
% Da einheitliche Koordinaten: Einfache Wiederaufnahme der Reduzierung der Strahlabtastrate (radial)
% -> Anschließende Interpolation um das gesamte Bild in voller Auflösung zu erhalten.

\subsection*{Auswahl des Eyetrackers}
% Da Renderoptionen existieren: 
% -> Arbeitspaket: Auswahl des Eyetracker um Mausposition schließlich mit Blickposition zu ersetzen
% -> HMD vs. Statisches am Bildschirm
% -> Integration der Tobii Pro SDK
% -> Umrechnung der Koordinaten des Eyetrackers in VolumeRenderWidget-Koordinaten

\subsection*{Erstellen von Messwerten}
% Idee: Messung von Kernelzeiten um verschiedene Verfahren besser vergleichen zu können und Messung der gesamten Ausführung um Gefühl für den Overhead der Kernel-Enqueues und der paintGL() Methode zu erhalten und die "echte" Performanz, die der Nutzer erfährt, zu bestimmen.
% -> Arbeitspaket: Integrieren von Möglichkeiten um Messwerte zu nehmen.
% -> Kernelzeiten durch volumerendercl-Objekt
% -> paintGL() Ausführungszeit mit QTime-Objekt
% -> Erstellen einer Mausbewegung über den Bildschirm. Dafür Unterteilung in 10x10 Grid
% -> Einrichten der Möglichkeit, diese zu reproduzieren, um die gleiche Mausbewegung mit den drei verschiedenen Verfahren zu testen (Standard, DDC, MDC)
% -> Erstellen von Messwerten für verschiedene Volumendaten, Transferfunktionen und Renderoptionen

\subsection*{Darstellen der Messwerte}
% Darstellung von Mausposition auf dem Bild und der gemessenenen Ausführungszeit.
% Kernelzeiten sind am wichtigsten, da diese die eigentliche Ausführungszeit der unterschiedlichen Methoden repräsentieren.
% Overhead muss nicht extra dargestellt werden, da relativ Konstant.
% -> Arbeitspaket: Darstellen der Messwerte durch Heatmaps
% -> Messen der Auslastung der GPU, wie Warps und Speicherbanks, mit CodeXL (gab aber Probleme und hat schließlich nicht funktioniert.)

\todo{Vorüberlegungen zur Umsetzung und daraus entstandene Arbeitspakete beschreiben.}