% Entwurf: Projekt, Raytracer, (Auswahl des) Eyetracker, Vorüberlegungen zur Umsetzung / Integration, Grundidee zur Umsetzung
% Entwurfsziele an die Umsetzungs
\chapter{Entwurf}\label{chap::design}
Die Implementierung dieser Arbeit beruht auf einem Visual Studio Projekt zum Volumen Rendering von Valentin Bruder.
Der erste Abschnitt des Entwurfskapitels beinhaltet den Ausgangspunkt der Implementierung dieser Arbeit in Form einer Beschreibung des ursprünglichen Projekts.
Dies umfasst die allgemeine Architektur der Anwendung und die Umsetzung des Volumenrenderings durch eine Implementierung eines Raycasters als OpenCL Kernel.
Der zweite Abschnitt des Kapitels umfasst Überlegungen für die Erweiterung des Projektes, bezüglich des Ausgangspunktes wie er im ersten Abschnitt beschrieben wurde und dem Ziel dieser Arbeit, sowie die daraus entstandenen Arbeitspakete und die Ansätze für ihre Integration in das bestehende Projekt.

\section{Projekt}\label{sec::proj}
% QT
Das Visual Studio Projekt, welches als Ausgangspunkt dient, ist eine auf QT basierende Anwendung.
QT ist ein vollständiges Cross-Platform Softaware Development Framework, welches in c++ entwickelt wurde, und ermöglicht die einfache Erstellung von Anwendungen mit Benutzeroberflächen und bietet außerdem eine Vielzahl von Bibliotheken, die für eine leichtere und schnellere Entwicklung von Programmen genutzt werden können.

% Struktur von QT
Die Hauptelemente für die QT Benutzeroberfläche sind QT Widgets.
Widgets können Daten darstellen und Nutzereingaben erkennen.
Außerdem stellt ein Widget selbst ein Container für weitere Widgets dar, welche in diesem gruppiert werden.
Innerhalb eines Widgets können Elemente platziert werden, welche Informationen, mögliche Operationen oder Nutzereingaben repräsentieren.
Für die bequeme Erstellung der grafischen Oberfläche bietet QT die Anwendung QT Designer.
Der QT Designer ermöglicht es, Widgets und andere Bausteine der grafischen Oberfläche per Drag und Drop anzuordnen.
Die durch den QT Designer definierte Oberfläche kann abgespeichert werden und wird von QT verwendet, um eine c++ Header File zu erstellen.
Dies ermöglicht es die verschiedenen Elemente der grafischen Oberfläche an die Logik der Anwendung zu binden.
\todo{Quelle zu QT einfügen.}

% Struktur des Projekts (verschiedene Widgets)
Das Projekt ist dementsprechend in c++ geschrieben und die grafische Oberfläche wurde mit Hilfe des QT Designers erstellt.
Die Oberfläche selbst hat eine Menüleiste, die es unter Anderem ermöglicht, Volumendaten oder Transferfunktionen zu laden oder auch aktive Transferfunktionen zu speichern sowie das Erstellen eines Screenshots des zuletzt berechneten Bildes.
Den Großteil der grafischen Oberfläche wird durch das Volumenrenderwidget ausgefüllt.
Das Volumenrenderwidget ist ein QT OpenGL Widget und kann für das Darstellen von OpenGL Grafiken verwendet werden.
Die berechneten Grafiken werden mit Hilfe des Volumenrenderwidgets dargestellt.
Neben dem Volumenrenderwidget gibt es noch ein Widget, welches in drei weitere Widgets unterteilt ist, mit denen Parameter für das Volumenrendering gesetzt werden können.
Das erste von ihnen ermöglicht das variieren der Abtastrate im Bildraum, also die Anzahl der Strahlen, die ausgesendet werden, sowie das Setzen der allgemeinen Abtastrate der ausgesendeten Strahlen.
Außerdem können hier weitere Rendering Parameter festgelegt werden, wie die Hintergrundfarbe oder ob Voxel beim Abtasten interpoliert werden.
Das zweite Widget ist ein Farbenrad, welches für die einfache Auswahl der Farben einzelner Kontrollpunkte der Transferfunktion verwendet werden kann.
Das dritte Widget ermöglicht schließlich das Setzen von Kontrollpunkten der Transferfunktion innerhalb eines Diagramms.
Die x-Richtung gibt die Dichte, auf die sich ein Kontrollpunkt bezieht an.
Die y-Richtung gibt seinen Opazitätswert an.
Die Werte zwischen zwei Kontrollpunkten werden entweder linear oder quadratisch interpoliert.
Daher gibt es immer mindestens einen Kontrollpunkt für den Dichtewert null und einen Kontrollpunkt für den Dichtewert eins.
\todo{Bitte auf Richtigkeit von diesem Teil prüfen, wie: Interpolation von Voxel und Einstellen der Transferfunkton.}

% Speziell VolumeRenderWidget: OpenCL, OpenGL Host Code
Das Volumenrenderwidget ist ein OpenGL Widget und für die Darstellung der berechneten Bilder zuständig.
Das QT Framework erlaubt es, das Widget in c++ Code mit Logik zu verknüpfen.
Dafür existiert in dem Projekt eine Klasse VolumeRenderWidget, welche von QOpenGLWidget erbt.
Die grundsätzliche Funktionalität zum Rendern in diesem Widget wird durch die Methode \texttt{paintGL()} ausgeführt.
Innerhalb dieser Methode wird der Code geschrieben, der für die Darstellung des Bildes nötig ist.
Das Darstellen auf dem Bildschirm beziehungsweise in dem Widget wird durch OpenGL realisiert.
OpenGL zeichnet dabei aber lediglich eine durch einen OpenCL Kernel zuvor generierte Textur auf ein Fullscreen Quad.
Das Management von OpenCL wird hier durch ein Objekt der Klasse \texttt{volumerendercl} geregelt.
Innerhalb der \texttt{paintGL()} Methode wird eine Methode dieses Objekts zum Starten des OpenCL Kernels für den Raycast des Volumenrenderings aufgerufen.
Das \texttt{volumerendercl} Objekt regelt die Handhabung der verschiedenen Parameter für den Kernel und die Unterteilung der übergebenen Anzahl an Strahlen in x- und y-Richtung, welche der Anzahl zu startenden Work-Items entspricht, in Work-Groups.
Außerdem startet es den Kernel, synchronisiert einen gemeinsamen Stopp und speichert die benötigte Zeit der letzten Ausführung des Kernels.
Die berechneten Werte der einzelnen Work-Items können bei der Ausführung des Kernels direkt in die OpenGL Textur geschrieben werden.
Daher kann nach der Ausführung der aufgerufenen Methode des \texttt{volumerendercl} Objekts die Textur direkt gezeichnet werden.
Mit Hilfe von QT Funktionen und der Information über die Ausführungszeit des Kernels werden anschließend noch ein paar Overlays gezeichnet.
Unter Anderem eine Anzeige der ungefähren möglichen Anzahl an Bildern pro Sekunde der letzten Ausführungen, um die Ausführungsdauer des Kernels abschätzen zu können.

% Raycaster: Raycastkernel
\subsection*{Raycaster}
% Raycaster: wichtige Parameter: in, out; Ungefährerer Aufbau: Sampling Loop durch das Volumen;
Der eigentliche Raycast passiert in einem OpenCL Kernel.
Die OpenCL Objekte werden von dem \texttt{volumerendercl} Objekt gehandhabt, dessen Methoden innerhalb der \texttt{paintGL()} Methode aufgerufen werden.
Das \texttt{volumerendercl} Objekt regelt auch die Übergabe der Parameter an den Raycast Kernel.
Dies sind Parameter wie Volumendaten, Transferfunktionswerte und Strahlabtastrate zum lesen, sowie eine 2D-Textur zum schreiben für die berechneten Farbwerte der einzelnen Work-Items.
Jedes Work-Item besitzt eine 2D-ID, die einer Position in der Ausgabetextur zugewiesen bekommt.
Ein Work-Item ist für das Abtasten eines Strahls verantwortlich.
Ein Strahl hat als Ursprung die Position der Kamera und entsprechend seiner ID, beziehungsweise Texturkoordinaten, wird seine Richtung bestimmt.
Abhängig von der Abtastrate des Strahls, berechnet sich die Schrittgröße für das Abtasten. 
Ausgehend von dem Schnittpunkt des Strahls mit der Bildebene wird nun in einer Schleife der Strahl schrittweise abgetastet.
Dabei wird für jeden Schritt die aktuelle Position bestimmt, welche normiert und dann dafür genutzt wird, um in dem 3D-Volumen Objekt den Dichtewert für diese Position zu bestimmen.
Mit dem Dichtewert und den Daten der Transferfunktion wird anschließend ein Farbwert berechnet.
Dieser Farbwert wird mit den bisherigen gesammelten Farbwerten des Strahls verrechnet, so dass am Ende der Abtastschleife ein einziger Farbwert für den Strahl existiert.
Der Farbwert wird zum Schluss an die entsprechende Texturkoordinate in der Ausgabetextur gespeichert.
\todo{Bild für das Abtasten des Strahls einfügen. Entweder hier oder bei Basics mit Volumenrendering und dann dorthin verweisen.}

%  Raycaster: Spezielle Eigenschaften, die aktiviert und deaktiviert werden können: ESS, Interpolation, AO
Der Raycast Kernel hat außer der grundlegenden Raycast Funktion noch weitere Eigenschaften, die die Performanz der Ausführung und die Qualität des Bildes verbessern.
So kann \emph{Empty Space Skipping} aktiviert werden, um größere Bereiche mit rein transparenten Voxeln zu überspringen.
Dies wird mit Hilfe eines zuvor gröber Berechneten Volumen ermöglicht.
Da das Volumen nur eine begrenzte Auflösung hat aber an einer beliebigen Position ein Wert aus dieser 3D-Textur abgerufen werden kann, muss angegeben werden, wie dieser Wert abhängig von den umliegenden Voxel bestimmt wird.
Daher kann hier gewählt werden, dass beim Auslesen des Dichtewerts an einer bestimmten Position des Volumens, dieser interpoliert wird.
Außerdem kann eine Orthografische Sicht des Volumens aktiviert werden, indem die Strahlen parallel ausgesendet werden und für solide Oberflächen gibt es die Möglichkeit, den Effekt der \emph{Ambient Occlusion} darzustellen.
\todo{Beschreibung der Funktionsweise des Raycasters für das Volumenrendering in dem Projekt.}

\section{Arbeitspakete und Integration}\label{sec::workpacks}
Ausgehend von der in Abschnitt \ref{sec::proj} beschriebenen Ausgangslage des Projekts, wurden einige Vorüberlegungen und Arbeitspakete erstellt, welche das Ziel hatten, das Projekt so zu erweitern, dass die Aspekte des wahrnehmungsorientierten Volumenrendering veranschaulicht und umgesetzt werden können.
Im folgenden werden die für dieses Ziel entstandenen Vorüberlegungen und daraus erstellte Arbeitspakete aufgeführt und die dazugehörigen Ansätze zur Integration in das bestehende Projekt skizziert.
Genauere Angaben zur Implementierung bestimmter Arbeitspakete werden im Kapitel \ref{chap::impl} vorgestellt.

\subsection*{Einarbeitung in das Projekt}
Das erste Arbeitspaket, welches nicht zu vernachlässigen ist, war die Einarbeitung in das Projekt beziehungsweise in die bestehende Implementierung.
Dies erforderte das Einarbeiten in einige Grundlagen der c++ Programmierung sowie das Einarbeiten in den grundlegenden Umgang mit dem QT Framework.
Da das Projekt ein Visual Studio Projekt ist und Programmierschnittstellen wie OpenCL oder auch QT verwendet, war eine kleine Einarbeitung in das richtige Verlinken der Bibliotheken mit dem Projekt auch Teil von diesem Arbeitspaket.

\subsection*{Simulieren der Blickposition}
% Eyetracker ersetzt durch Maus
% Widget kann auf Mausbewegungsevents reagieren
% -> Arbeitspaket: Abspeichern der Mausposition in globaler Variable
% -> Übergabe der Mausposition an den Kernel

\subsection*{Reduzierung der Strahlabtastrate im fovealen Bereich}
% Performanz erhöhen da Kernelzeit in äußeren Bereichen reduziert wird
% Reduzierung der Strahlabtastrate sollte im äußeren Bereich kaum auffallen
% -> Arbeitspaket: Verwenden der übergebenen Mausposition um im äußeren Bereich die Abtastrate des Strahls zu reduzieren
% -> Mausposition in Bildkoordinaten; Radial abhängig zur Distanz eines Work-Items zur Mausposition Samples reduzieren

\subsection*{Reduzierung der Strahldichte im fovealen Bereich}
% Immernoch gleiche Anzahl an gestarteten Work-Items
% Diese Anzahl reduzieren, da bei weniger Work-Groups die Ausführungszeit des Kernels auch schneller beendet sein sollte
% Erste Idee: Einabuen einer Linse. Diese wird entsprechend vor die Kamera platziert, so dass bei weniger ausgesendeten Strahlen die Strahlen so gebrochen werden, dass trotzdem an der entsprechenden Position mehr Strahlsamples berechnet werden und an den äußeren eher weniger.
% Problem: Interpolation und Berechnen der Linse beziehungsweise die richtige neue Richtung (und Texturkoordinate) des Strahls, der bisher ganz normal ausgesendet wird (Immernoch je Texel ein Strahl / Work-Item).
% Neue Idee: Zwei verschiedene Kernelaufrufe. Der erste berechnet das Bild mit einem viertel der Auflösung über den gesamten Texturbereich, der zweite berechnet das Bild mit der normalen Auflösung aber nur in einem kleinen Bereich um die Mausposition.
% Danach werden beide übereinander platziert.
% Problem: Bilder in verschiedenen Auflösung. Daher Mausposition normieren auf [0,1]^2. Reduzieren der Strahlsamples wurde bei diesem Ansatz nicht verwendet.
% -> Arbeitspaket: Berechnen des Bildes in zwei verschiedenen Auflösungen und Zusammenfügen beider für ein Bild in gesamter Auflösung. 

\subsection*{Indize-Mapping}
% Ziel: Drei unterschiedliche Auflösungen, die übereinander gelegt werden.
% Mit normierten Koordinaten zu rechnen war aufwändig
% -> drei Berechnungen auf dem gesamten Bild aber je nach Auflösung werden Work-Items schon früh discarded.
% -> erster Test hat gezeigt, dass 1. Drei Kernel Enqueues nacheinander, die jeweils den Raycast machen, aufwändig sind und 2. das discarden von Work-Items keinerlei Performance bringt. Lag daran, dass Work-Items in verschiedenen Work-Groups sind und auch wenn alle bis auf eines früh discarded, muss der gesamte Thread-Block (auf den eine Work-Group vermutlich gemappt ist) weiterarbeiten.
% -> Daher: Zwei oder mehr Raycast Kernel Aufrufe wollte vermeiden, wegen möglichen Overhead und neuer Ansatz: Drei unterschiedlich aufgelöste Bildbereiche bei einem Renderdurchlauf durch das Mapping von Indizes.
% -> Arbeitspaket: Mapping von Indizes um bei einem einzigen Raycast Kernel Aufruf trotzdem drei verschieden aufgelöste Bereiche zu erreichen.
% Da einheitliche Koordinaten: Einfache Wiederaufnahme der Reduzierung der Strahlabtastrate (radial)
% -> Anschließende Interpolation um das gesamte Bild in voller Auflösung zu erhalten.

\subsection*{Auswahl des Eyetrackers}
% Da Renderoptionen existieren: 
% -> Arbeitspaket: Auswahl des Eyetracker um Mausposition schließlich mit Blickposition zu ersetzen
% -> HMD vs. Statisches am Bildschirm
% -> Integration der Tobii Pro SDK
% -> Umrechnung der Koordinaten des Eyetrackers in VolumeRenderWidget-Koordinaten

\subsection*{Erstellen von Messwerten}
% Idee: Messung von Kernelzeiten um verschiedene Verfahren besser vergleichen zu können und Messung der gesamten Ausführung um Gefühl für den Overhead der Kernel-Enqueues und der paintGL() Methode zu erhalten und die "echte" Performanz, die der Nutzer erfährt, zu bestimmen.
% -> Arbeitspaket: Integrieren von Möglichkeiten um Messwerte zu nehmen.
% -> Kernelzeiten durch volumerendercl-Objekt
% -> paintGL() Ausführungszeit mit QTime-Objekt
% -> Erstellen einer Mausbewegung über den Bildschirm. Dafür Unterteilung in 10x10 Grid
% -> Einrichten der Möglichkeit, diese zu reproduzieren, um die gleiche Mausbewegung mit den drei verschiedenen Verfahren zu testen (Standard, DDC, MDC)
% -> Erstellen von Messwerten für verschiedene Volumendaten, Transferfunktionen und Renderoptionen

\subsection*{Darstellen der Messwerte}
% Darstellung von Mausposition auf dem Bild und der gemessenenen Ausführungszeit.
% Kernelzeiten sind am wichtigsten, da diese die eigentliche Ausführungszeit der unterschiedlichen Methoden repräsentieren.
% Overhead muss nicht extra dargestellt werden, da relativ Konstant.
% -> Arbeitspaket: Darstellen der Messwerte durch Heatmaps
% -> Messen der Auslastung der GPU, wie Warps und Speicherbanks, mit CodeXL (gab aber Probleme und hat schließlich nicht funktioniert.)

\todo{Vorüberlegungen zur Umsetzung und daraus entstandene Arbeitspakete beschreiben.}